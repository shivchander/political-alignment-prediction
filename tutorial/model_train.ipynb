{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x38tO77A2TBH",
        "colab_type": "code",
        "outputId": "18a05d69-3d4e-42ef-cf36-0ac6f7a8cc10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "from sklearn.metrics import  accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS\n",
        "from textblob import TextBlob\n",
        "from nltk.text import Text  \n",
        "from pandas import Series\n",
        "import seaborn as sns\n",
        "import nltk, string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk as nlp\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM, Bidirectional, CuDNNLSTM\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "STOPWORDS.add(\"rt\")\n",
        "STOPWORDS.add(\"s\")\n",
        "STOPWORDS.add(\"u\")\n",
        "STOPWORDS.add(\"amp\")\n",
        "STOPWORDS.add(\"th\")\n",
        "STOPWORDS.add(\"will\")\n",
        "STOPWORDS.add(\"t\")\n",
        "STOPWORDS.add(\"m\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XbDDHMrr8fu",
        "colab_type": "code",
        "outputId": "db6ccb5a-605c-42b8-aa5b-1f90bd50342d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9YG1d3u20RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/tweet/ExtractedTweets.csv\")\n",
        "df.dropna(axis = 0, inplace = True)\n",
        "df[\"Party_log\"] = [1 if each == \"Democrat\" else 0 for each in df.Party]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fftzxbGh3MvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_words = 10000  \n",
        "tokenizer = TweetTokenizer(reduce_len=True)\n",
        "tweets = df.copy()\n",
        "\n",
        "# cleaning\n",
        "tweet_arr = tweets.Tweet.to_numpy()\n",
        "tweet_list = []\n",
        "lemma = nlp.WordNetLemmatizer()\n",
        "\n",
        "for d in tweet_arr:\n",
        "    d = re.sub(r'http\\S+', '', d) #remove links\n",
        "    d = re.sub(\"[^a-zA-Z]\", \" \", d) #remove all characters except letters\n",
        "    d = d.lower() #convert all words to lowercase\n",
        "    d = nltk.word_tokenize(d) #split sentences into word\n",
        "    d = [word for word in d if not word in STOPWORDS] #remove the stopwords\n",
        "    d = [lemma.lemmatize(word) for word in d] #identify the correct form of the word in the dictionary\n",
        "    d = \" \".join(d)\n",
        "    tweet_list.append(d)\n",
        "\n",
        "tweet_arr = np.asarray(tweet_list)\n",
        "\n",
        "tweets['Tweet'] = tweet_arr\n",
        "\n",
        "# tokenizing\n",
        "tweets['Tweet'] = tweets.Tweet.apply(tokenizer.tokenize)\n",
        "\n",
        "# converting tweet tokens to freq dist ranks\n",
        "fdist = FreqDist(word for tweet in tweets.Tweet for word in tweet)\n",
        "terms = [term for term, count in fdist.most_common(top_words)]\n",
        "tweets.Tweet = tweets.Tweet.apply(lambda tweet:\n",
        "                                  [terms.index(term) if term in terms else 0 \n",
        "                                   for term in tweet])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrKaAqTb8894",
        "colab_type": "code",
        "outputId": "1ac72b63-08c1-41f0-f8b2-6055e776076c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# padding every tweet to max review length\n",
        "\n",
        "x = tweets.Tweet\n",
        "y = tweets.Party_log\n",
        "\n",
        "max_review_length = 50 \n",
        "x = sequence.pad_sequences(x, maxlen=max_review_length)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(86460, 50)\n",
            "(86460,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8i38seLVF8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sourced from \n",
        "import keras.backend as K\n",
        "def matthews_correlation(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "    y_pred_neg = 1 - y_pred_pos\n",
        "\n",
        "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
        "    y_neg = 1 - y_pos\n",
        "\n",
        "    tp = K.sum(y_pos * y_pred_pos)\n",
        "    tn = K.sum(y_neg * y_pred_neg)\n",
        "\n",
        "    fp = K.sum(y_neg * y_pred_pos)\n",
        "    fn = K.sum(y_pos * y_pred_neg)\n",
        "\n",
        "    numerator = (tp * tn - fp * fn)\n",
        "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "\n",
        "    return numerator / (denominator + K.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT1fskXMBLeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  embedding_vecor_length = 32\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words, embedding_vecor_length,\n",
        "                      input_length=max_review_length))\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, padding='same',\n",
        "                   activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Bidirectional(LSTM(256)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam', metrics=[matthews_correlation])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvGgje6pHF19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stats(y_test, y_pred):\n",
        "  from sklearn.metrics import matthews_corrcoef, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "  print('MCC: ', matthews_corrcoef(y_test, np.round(y_pred)))\n",
        "  print('Accuracy Score: ', accuracy_score(y_test, np.round(y_pred)))\n",
        "  print('F1 Score: ', f1_score(y_test, np.round(y_pred)))\n",
        "  print('Confusion Matrix ')\n",
        "  print(confusion_matrix(y_test, np.round(y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQxe3pXxDnee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHlXahmyFqQ0",
        "colab_type": "code",
        "outputId": "f1b1c8b0-5561-4476-e2bc-e19aa1eb94ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = get_model()\n",
        "print(model.summary())\n",
        "history = model.fit(x_train, y_train, epochs=5,\n",
        "                    batch_size=64, validation_split=0.33)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 32)            320000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 50, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 25, 32)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 25, 512)           591872    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 25, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,540,513\n",
            "Trainable params: 3,540,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 46342 samples, validate on 22826 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "46342/46342 [==============================] - 214s 5ms/step - loss: 0.5310 - matthews_correlation: 0.4243 - val_loss: 0.5033 - val_matthews_correlation: 0.5022\n",
            "Epoch 2/5\n",
            "46342/46342 [==============================] - 197s 4ms/step - loss: 0.3687 - matthews_correlation: 0.6624 - val_loss: 0.4582 - val_matthews_correlation: 0.5555\n",
            "Epoch 3/5\n",
            "46342/46342 [==============================] - 198s 4ms/step - loss: 0.2625 - matthews_correlation: 0.7748 - val_loss: 0.5128 - val_matthews_correlation: 0.5447\n",
            "Epoch 4/5\n",
            "46342/46342 [==============================] - 196s 4ms/step - loss: 0.1498 - matthews_correlation: 0.8817 - val_loss: 0.6964 - val_matthews_correlation: 0.5280\n",
            "Epoch 5/5\n",
            "46342/46342 [==============================] - 195s 4ms/step - loss: 0.0881 - matthews_correlation: 0.9348 - val_loss: 0.9953 - val_matthews_correlation: 0.5250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-0TmxHeGwps",
        "colab_type": "code",
        "outputId": "5fcdf705-caa8-4e46-c20f-5bb9f179aa19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "y_pred = model.predict(x_test, use_multiprocessing=True)\n",
        "get_stats(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC:  0.5388015476495792\n",
            "Accuracy Score:  0.7698935924126764\n",
            "F1 Score:  0.7520099719538798\n",
            "Confusion Matrix \n",
            "[[7280 1728]\n",
            " [2251 6033]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RJRLQ3Hv2F_",
        "colab_type": "code",
        "outputId": "d1ca5ac9-a8aa-49b9-f928-bf6400b26eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/tweet/model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/My Drive/tweet/model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGWPUoAhXbtm",
        "colab_type": "code",
        "outputId": "f7f63556-e71c-4ac6-a608-ff293ea5cb58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load json and create model\n",
        "json_file = open('/content/drive/My Drive/tweet/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/My Drive/tweet/model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m7lhthlMPYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_input(tweet):\n",
        "    tweet = re.sub(r'http\\S+', '', tweet) #remove links\n",
        "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet) #remove all characters except letters\n",
        "    tweet = tweet.lower() #convert all words to lowercase\n",
        "    tweet = nltk.word_tokenize(tweet) #split sentences into word\n",
        "    tweet = [word for word in tweet if not word in STOPWORDS] #remove the stopwords\n",
        "    tweet = [lemma.lemmatize(word) for word in tweet] #identify the correct form of the word in the dictionary\n",
        "    tweet = \" \".join(tweet)\n",
        "    return tweet\n",
        "\n",
        "def convert_input(tweet):\n",
        "    tweet = clean_input(tweet)\n",
        "    # tokenizing\n",
        "    tweet = tokenizer.tokenize(tweet)\n",
        "    # converting tweet tokens to freq dist ranks\n",
        "    terms = [term for term, count in fdist.most_common(top_words)]\n",
        "    encoded_tweet = [terms.index(term) if term in terms else 0 for term in tweet]\n",
        "    tweet_arr = np.array([encoded_tweet])\n",
        "    padded_tweet = sequence.pad_sequences(tweet_arr, maxlen=max_review_length)\n",
        "    return padded_tweet\n",
        "\n",
        "def predict_tweet(tweet):\n",
        "    tweet = convert_input(tweet)\n",
        "    prediction = loaded_model.predict(tweet)\n",
        "    print(prediction)\n",
        "    if prediction > 0.5:\n",
        "      return 'Democrat'\n",
        "    else:\n",
        "      return 'Republican'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNrqbkG4MqPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictions(tweets):\n",
        "    stats = {}\n",
        "    for t in tweets:\n",
        "        res = predict_tweet(t)\n",
        "        if res in stats:\n",
        "            stats[res] += 1\n",
        "        else:\n",
        "            stats[res] = 1\n",
        "    return stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2HWMEKGQXRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "\n",
        "keys = dict(consumer_key=\"yuNQZSADRNqRiDj0U3oOWEaE9\",\n",
        "            consumer_secret=\"OuJVoxDFBTy7wiePcEW0d0RkuHSaQwr5niBTWAEMdASnTWcOrX\",\n",
        "            access_token='1168231254308712449-XuhViryRpYsrhYuhpETXImWFTHViis',\n",
        "            access_token_secret='ZphiLvqrYIZpYsjGLeoD8lDDxU4ZgXC2wQT1WXpwJlykU'\n",
        "            )\n",
        "\n",
        "\n",
        "__author__ = 'Shivchander Sudalairaj'\n",
        "\n",
        "\n",
        "class Tweet:\n",
        "    def __init__(self, user_handle):\n",
        "        \"\"\"\n",
        "        :param user_handle: twitter username without '@' symbol\n",
        "        :return: class method\n",
        "        \"\"\"\n",
        "        self._consumer_key = keys['consumer_key']\n",
        "        self._consumer_secret = keys['consumer_secret']\n",
        "        self._access_token = keys['access_token']\n",
        "        self._access_token_secret = keys['access_token_secret']\n",
        "\n",
        "        # configure OAUTH\n",
        "        self.auth = tweepy.OAuthHandler(self._consumer_key, self._consumer_secret)\n",
        "        self.auth.set_access_token(self._access_token, self._access_token_secret)\n",
        "\n",
        "        # set up tweepy client\n",
        "        self.api = tweepy.API(\n",
        "            self.auth,\n",
        "            wait_on_rate_limit=True,\n",
        "            wait_on_rate_limit_notify=True,\n",
        "            timeout=60,\n",
        "            compression=True\n",
        "        )\n",
        "\n",
        "        self.user_handle = user_handle\n",
        "\n",
        "    def get_friends(self):\n",
        "        \"\"\"\n",
        "        :return: array containing the IDs of users being followed by self.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # get friends ids\n",
        "            friends_ids = []\n",
        "            for friend in tweepy.Cursor(self.api.friends_ids, screen_name=self.user_handle).pages():\n",
        "                friends_ids.append(friend)\n",
        "\n",
        "            # get twitter handles\n",
        "            friends_handles = [user.screen_name for user in self.api.lookup_users(user_ids=friends_ids)]\n",
        "            return friends_handles\n",
        "\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return []\n",
        "\n",
        "    def get_followers(self):\n",
        "        \"\"\"\n",
        "        :return: array containing the IDs of users following self.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # get friends ids\n",
        "            followers_ids = []\n",
        "            for follower in tweepy.Cursor(self.api.followers_ids, id=self.user_handle).pages():\n",
        "                followers_ids.append(follower)\n",
        "\n",
        "            # get twitter handles\n",
        "            followers_handles = [user.screen_name for user in self.api.lookup_users(user_ids=followers_ids)]\n",
        "            return followers_handles\n",
        "\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return []\n",
        "\n",
        "    def get_tweets(self, limit=100):\n",
        "        \"\"\"\n",
        "        :param limit: max limit of tweets\n",
        "        :return: array containing the tweets from self.user_handle\n",
        "        \"\"\"\n",
        "        try:\n",
        "            tweets = []\n",
        "            for obj in tweepy.Cursor(self.api.user_timeline, screen_name=self.user_handle,\n",
        "                                     include_rts=False, tweet_mode='extended').items(limit):\n",
        "                if len(tweets) < limit:\n",
        "                    tweets.append(obj.full_text)\n",
        "                else:\n",
        "                    break\n",
        "            return tweets\n",
        "\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return []\n",
        "\n",
        "    def get_retweets(self, limit=100):\n",
        "        \"\"\"\n",
        "        :param limit: max limit of tweets\n",
        "        :return: array containing the retweets from self.user_handle\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            retweets = []\n",
        "            for obj in tweepy.Cursor(self.api.user_timeline, screen_name=self.user_handle,\n",
        "                                     include_rts=True, tweet_mode='extended').items():\n",
        "                if obj.full_text.startswith('RT'):\n",
        "                    if len(retweets) < limit:\n",
        "                        retweets.append(obj.full_text)\n",
        "                    else:\n",
        "                        break\n",
        "            return retweets\n",
        "\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return []\n",
        "\n",
        "    def get_favtweets(self, limit=100):\n",
        "        \"\"\"\n",
        "        :param limit: max limit of tweets\n",
        "        :return: array containing the tweets favorite-ed by self.user_handle\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            favtweets = []\n",
        "            for obj in tweepy.Cursor(self.api.favorites, id=self.user_handle).items(limit):\n",
        "                if len(favtweets) < limit:\n",
        "                    favtweets.append(obj.text)\n",
        "                else:\n",
        "                    break\n",
        "            return favtweets\n",
        "\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return []\n",
        "\n",
        "    def get_location(self):\n",
        "        \"\"\"\n",
        "        :return: location of the self\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(self.api.get_user(screen_name=self.user_handle).location)\n",
        "        except tweepy.TweepError:\n",
        "            print('Oops somethings not right, good luck figuring out what')\n",
        "            return None\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUYj4-oiOcTO",
        "colab_type": "code",
        "outputId": "fff92832-7543-4bbf-866d-fe08e8a25772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(twats)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM01kMU-NZMj",
        "colab_type": "code",
        "outputId": "f2d9c9dd-dd7f-43f1-b4a2-81b9f34759d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x = Tweet('michaelcburgess')\n",
        "twats = x.get_tweets()\n",
        "print(make_predictions(twats))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00011886]]\n",
            "[[3.7343452e-06]]\n",
            "[[0.9999999]]\n",
            "[[0.00601882]]\n",
            "[[1.0605115e-05]]\n",
            "[[0.02232434]]\n",
            "[[0.21906336]]\n",
            "[[0.00027008]]\n",
            "[[0.00207869]]\n",
            "[[0.9240636]]\n",
            "[[0.21803892]]\n",
            "[[1.1970317e-07]]\n",
            "[[1.1483521e-05]]\n",
            "[[0.06434233]]\n",
            "[[5.4345306e-05]]\n",
            "[[0.00015291]]\n",
            "[[0.00040688]]\n",
            "[[0.7604855]]\n",
            "[[0.99788314]]\n",
            "[[0.11742231]]\n",
            "[[0.]]\n",
            "[[0.00105121]]\n",
            "[[0.00054462]]\n",
            "[[0.01844192]]\n",
            "[[2.7575018e-07]]\n",
            "[[0.9570874]]\n",
            "[[0.00486509]]\n",
            "[[0.03847144]]\n",
            "[[0.46559602]]\n",
            "[[1.]]\n",
            "[[0.06542029]]\n",
            "[[0.99882096]]\n",
            "[[0.9999999]]\n",
            "[[0.829195]]\n",
            "[[0.99520206]]\n",
            "[[0.00028185]]\n",
            "[[0.22009279]]\n",
            "[[5.902534e-07]]\n",
            "[[0.01150742]]\n",
            "[[0.38496304]]\n",
            "[[0.06976964]]\n",
            "[[0.9952192]]\n",
            "[[0.98852867]]\n",
            "[[0.00320679]]\n",
            "[[0.2165661]]\n",
            "[[0.07545079]]\n",
            "[[0.00017789]]\n",
            "[[0.37562644]]\n",
            "[[0.15925439]]\n",
            "[[3.4425448e-06]]\n",
            "[[0.01492222]]\n",
            "[[0.01836975]]\n",
            "[[0.12205904]]\n",
            "[[0.50705713]]\n",
            "[[0.5148638]]\n",
            "[[0.02035884]]\n",
            "[[0.00257082]]\n",
            "[[0.99985325]]\n",
            "[[0.22752823]]\n",
            "[[0.00098995]]\n",
            "[[3.388642e-05]]\n",
            "[[0.00017865]]\n",
            "[[7.479429e-06]]\n",
            "[[2.7436818e-05]]\n",
            "[[0.00530713]]\n",
            "[[0.94214666]]\n",
            "[[1.0733322e-06]]\n",
            "[[0.01718355]]\n",
            "[[0.08762701]]\n",
            "[[0.01053857]]\n",
            "[[4.2515578e-07]]\n",
            "[[3.2050815e-05]]\n",
            "[[0.17066969]]\n",
            "[[0.00018541]]\n",
            "[[0.00011457]]\n",
            "[[1.1793953e-05]]\n",
            "[[0.99018705]]\n",
            "[[0.23448487]]\n",
            "[[0.98718864]]\n",
            "[[0.3938732]]\n",
            "[[0.37172747]]\n",
            "[[0.0040501]]\n",
            "[[0.9776584]]\n",
            "[[0.9766382]]\n",
            "[[0.00402588]]\n",
            "[[0.03587943]]\n",
            "[[0.00058682]]\n",
            "[[0.00064143]]\n",
            "[[0.7932802]]\n",
            "[[0.04770805]]\n",
            "[[0.11351771]]\n",
            "[[0.01269164]]\n",
            "[[0.00086173]]\n",
            "[[0.99975437]]\n",
            "[[0.9757817]]\n",
            "[[0.99995065]]\n",
            "[[0.6916403]]\n",
            "[[0.00028796]]\n",
            "[[0.99897015]]\n",
            "[[0.82071906]]\n",
            "{'Republican': 73, 'Democrat': 27}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzFuaEIRenVZ",
        "colab_type": "text"
      },
      "source": [
        "https://xiangyutang2.github.io/tweet-classification/\n",
        "https://www.kaggle.com/zaslee/bert-text-classification-demo-nlp-experiment\n",
        "https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
        "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\n",
        "https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb\n",
        "https://github.com/sebsk/CS224N-Project\n",
        "https://colab.research.google.com/drive/18SVeIFXWCiA9HL4WVCAFxlfH59ez6atc\n",
        "\n"
      ]
    }
  ]
}